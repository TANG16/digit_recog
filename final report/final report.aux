\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lecun1998gradient}
\citation{liu2003handwritten}
\citation{lowe2004distinctive}
\citation{dalal2005histograms}
\citation{lecun1998gradient}
\@writefile{toc}{\contentsline {section}{\numberline {1}Problem Description}{1}{section.1}}
\newlabel{sec:problem}{{1}{1}{Problem Description}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data Description}{1}{section.2}}
\newlabel{sec:data}{{2}{1}{Data Description}{section.2}{}}
\citation{lecun1998gradient}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Digits from MNIST Dataset\relax }}{2}{figure.caption.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Normalization of the dataset: (a)\nobreakspace  {}MNIST(original) (b)\nobreakspace  {}MNIST(normalized)\relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:norm}{{2}{2}{Normalization of the dataset: (a)~MNIST(original) (b)~MNIST(normalized)\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{2}{section.3}}
\newlabel{sec:methods}{{3}{2}{Methods}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Preprocessing}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Normalization}{2}{subsubsection.3.1.1}}
\citation{dalal2005histograms}
\citation{felzenszwalb2010object}
\citation{felzenszwalb2010object}
\citation{felzenszwalb2010object}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Feature Extraction}{3}{subsubsection.3.1.2}}
\citation{lowe2004distinctive}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  (a)handwritten digits 0-9 from MNIST (b)HOG features of handwritten digits 0-9\relax }}{4}{figure.caption.4}}
\newlabel{fig:hog}{{3}{4}{(a)handwritten digits 0-9 from MNIST (b)HOG features of handwritten digits 0-9\relax }{figure.caption.4}{}}
\citation{yilmaz2006object}
\citation{dalal2005histograms}
\citation{lowe2004distinctive}
\citation{altman1992introduction}
\citation{soltanzadeh2004recognition}
\citation{bottou1994comparison}
\citation{liu2003handwritten}
\citation{le1990handwritten}
\citation{lecun1995comparison}
\citation{krizhevsky2012imagenet}
\citation{cirecsan2011convolutional}
\citation{ciresan2012multi}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Handwritten digits with their SIFT features: (a)\nobreakspace  {}A handwritten 9 (b)\nobreakspace  {} A handwritten 0\relax }}{5}{figure.caption.6}}
\newlabel{fig:SIFT}{{4}{5}{Handwritten digits with their SIFT features: (a)~A handwritten 9 (b)~ A handwritten 0\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Dimension Reductions}{5}{subsubsection.3.1.3}}
\citation{altman1992introduction}
\citation{le1990handwritten}
\citation{lecun1995comparison}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The classification pipeline with $k$NN classifier\relax }}{6}{figure.caption.7}}
\newlabel{fig:pipeline-knn}{{5}{6}{The classification pipeline with $k$NN classifier\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Classification}{6}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}$k$-NN Classifier}{6}{subsubsection.3.2.1}}
\citation{tipping2001sparse}
\citation{krizhevsky2012imagenet}
\citation{lecun1998gradient}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The classification pipeline with SVM classifier\relax }}{7}{figure.caption.8}}
\newlabel{fig:pipeline-svm}{{6}{7}{The classification pipeline with SVM classifier\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}SVM Classifier}{7}{subsubsection.3.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}CNN Classifier}{7}{subsubsection.3.2.3}}
\citation{lecun1998gradient}
\citation{cherer2010evaluation}
\citation{vedaldi15matconvnet}
\@writefile{toc}{\contentsline {paragraph}{Preprocessing}{8}{section*.9}}
\@writefile{toc}{\contentsline {paragraph}{Overall Architecture}{8}{section*.10}}
\@writefile{toc}{\contentsline {subparagraph}{Original Architecture}{8}{section*.11}}
\@writefile{toc}{\contentsline {subparagraph}{Modified Architecture}{8}{section*.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The architecture of CNN(Lenet model)\relax }}{9}{figure.caption.12}}
\newlabel{fig:arch1}{{7}{9}{The architecture of CNN(Lenet model)\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The architecture of CNN(Our model)\relax }}{10}{figure.caption.13}}
\newlabel{fig:arch2}{{8}{10}{The architecture of CNN(Our model)\relax }{figure.caption.13}{}}
\citation{lecun1989backpropagation}
\citation{simard2003best}
\@writefile{toc}{\contentsline {paragraph}{Training}{11}{section*.15}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{11}{section.4}}
\newlabel{sec:res}{{4}{11}{Results}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{11}{section.5}}
\newlabel{sec:res}{{5}{11}{Results}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}$k$-NN classifier}{11}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The result of digit recognition of classification pipeline with $k$NN classifier\relax }}{12}{figure.caption.16}}
\newlabel{fig:knn}{{9}{12}{The result of digit recognition of classification pipeline with $k$NN classifier\relax }{figure.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Accuracy and running time of classification pipeline with $k$-NN classifier on average\relax }}{12}{table.caption.17}}
\newlabel{tab:knn}{{1}{12}{Accuracy and running time of classification pipeline with $k$-NN classifier on average\relax }{table.caption.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Comparison on Normalization}{13}{subsubsection.5.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Comparison on Feature Selection}{13}{subsubsection.5.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Comparison on Dimension Reduction Methods}{13}{subsubsection.5.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}SVM classifier}{13}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The classification accuracy of SVM with polynomial kernels under different degrees\relax }}{14}{figure.caption.18}}
\newlabel{fig:svm-poly}{{10}{14}{The classification accuracy of SVM with polynomial kernels under different degrees\relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Accuracy on CNN classifiers\relax }}{14}{table.caption.20}}
\newlabel{cnnerror}{{2}{14}{Accuracy on CNN classifiers\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}CNN classifier}{14}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The classification accuracy of SVM with rbf kernels under different $\sigma $\relax }}{15}{figure.caption.19}}
\newlabel{fig:svm-rbf}{{11}{15}{The classification accuracy of SVM with rbf kernels under different $\sigma $\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The classification accuracy of SVM with rbf kernels under different $\sigma $\relax }}{15}{figure.caption.21}}
\newlabel{fig:svm-rbf}{{12}{15}{The classification accuracy of SVM with rbf kernels under different $\sigma $\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Error Rates of CNN classifier on Train and Validation Set with Growing Training Samples \relax }}{16}{figure.caption.22}}
\newlabel{fig:cnnerror}{{13}{16}{Error Rates of CNN classifier on Train and Validation Set with Growing Training Samples \relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{16}{section.6}}
\bibstyle{plain}
\bibdata{references}
\bibcite{altman1992introduction}{1}
\bibcite{bottou1994comparison}{2}
\bibcite{ciresan2012multi}{3}
\bibcite{cirecsan2011convolutional}{4}
\bibcite{dalal2005histograms}{5}
\bibcite{felzenszwalb2010object}{6}
\bibcite{krizhevsky2012imagenet}{7}
\bibcite{le1990handwritten}{8}
\bibcite{lecun1989backpropagation}{9}
\bibcite{lecun1998gradient}{10}
\bibcite{lecun1995comparison}{11}
\bibcite{liu2003handwritten}{12}
\bibcite{lowe2004distinctive}{13}
\bibcite{simard2003best}{14}
\bibcite{soltanzadeh2004recognition}{15}
\bibcite{tipping2001sparse}{16}
\bibcite{yilmaz2006object}{17}
